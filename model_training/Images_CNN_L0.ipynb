{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pickle\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h2 id=\"settings\"> Settings </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 128\n",
    "img_height = 128\n",
    "img_width = 128\n",
    "data_dir = 'imagenes/product_images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load\n",
    "\n",
    "We load the clean data without records that do not contain images or where the images did not exist at the time of download (their URL returned a 404 error when loading)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_csv= ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(path_csv+'train_filtered.csv')\n",
    "val_data = pd.read_csv(path_csv+'val_filtered.csv')\n",
    "test_data = pd.read_csv(path_csv+'test_filtered.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LABEL ENCODERS FUNCTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "listdis = os.listdir('./artifacts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def encode_labels(train_data, val_data, test_data, column , category_level):\n",
    "    \n",
    "    train_labels = train_data[column]\n",
    "    val_labels = val_data[column]\n",
    "    test_labels = test_data[column]    \n",
    "\n",
    "    if 'label_encoder_level'+category_level+'.pkl' in listdis:\n",
    "        with open('artifacts/label_encoder_level'+category_level+'.pkl', 'rb') as f:\n",
    "            le = pickle.load(f)\n",
    "        print('found file')\n",
    "    else:\n",
    "        le = LabelEncoder()\n",
    "        print(\"don't found file\")\n",
    "\n",
    "    print(f\"num clases {le.classes_} \" )\n",
    "\n",
    "    num_classes = 13\n",
    "    train_label_le = le.transform(train_labels)\n",
    "    val_label_le = le.transform(val_labels)\n",
    "    test_label_le = le.transform(test_labels)\n",
    "\n",
    "    train_label_cate = to_categorical(train_label_le)\n",
    "    val_label_cate = to_categorical(val_label_le)\n",
    "    test_label_cate = to_categorical(test_label_le)\n",
    "\n",
    "    return train_label_cate, val_label_cate, test_label_cate, train_label_le, num_classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess create_dataset image function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [img_height, img_width])\n",
    "    image = image / 255.0  # Normalizar los p√≠xeles a [0, 1]\n",
    "    return image\n",
    "\n",
    "def create_dataset(data, image_column, labels):\n",
    "    image_paths = data[image_column].values\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "    dataset = dataset.map(lambda x, y: (preprocess_image(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------    L E V E L   1   ----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LABEL ENCODERS LEVEL 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carge\n",
      "num clases ['Appliances' 'Audio' 'Cameras & Camcorders' 'Car Electronics & GPS'\n",
      " 'Cell Phones' 'Computers & Tablets' 'Connected Home & Housewares'\n",
      " 'Health, Fitness & Beauty' 'Musical Instruments' 'Other'\n",
      " 'TV & Home Theater' 'Toys, Games & Drones' 'Video Games'] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LabelEncoder from version 1.3.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_labels, val_labels, test_labels, train_label_le, num_classes = encode_labels(train_data, val_data, test_data, 'subcat1_name', '1')\n",
    "\n",
    "#Compute the class weight\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(train_label_le), y=train_label_le)\n",
    "class_weight_dict = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = create_dataset(train_data, 'image', train_labels)\n",
    "val_ds = create_dataset(val_data, 'image', val_labels)\n",
    "test_ds = create_dataset(test_data, 'image', test_labels)\n",
    "\n",
    "train_ds = train_ds.shuffle(1000).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "      <th>image</th>\n",
       "      <th>subcat1_name</th>\n",
       "      <th>subcat2_name</th>\n",
       "      <th>subcat3_name</th>\n",
       "      <th>subcat4_name</th>\n",
       "      <th>subcat5_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mod. - Victoria Camera Accessory Kit - Hot Pink</td>\n",
       "      <td>HardGood</td>\n",
       "      <td>MOD. Victoria Camera Accessory Kit: Compatible...</td>\n",
       "      <td>imagenes/product_images/1285055.jpg</td>\n",
       "      <td>Cameras &amp; Camcorders</td>\n",
       "      <td>Digital Camera Accessories</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>Universal Camera Bags &amp; Cases</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              name      type   \n",
       "0  mod. - Victoria Camera Accessory Kit - Hot Pink  HardGood  \\\n",
       "\n",
       "                                         description   \n",
       "0  MOD. Victoria Camera Accessory Kit: Compatible...  \\\n",
       "\n",
       "                                 image          subcat1_name   \n",
       "0  imagenes/product_images/1285055.jpg  Cameras & Camcorders  \\\n",
       "\n",
       "                 subcat2_name subcat3_name subcat4_name   \n",
       "0  Digital Camera Accessories        Other        Other  \\\n",
       "\n",
       "                    subcat5_name  \n",
       "0  Universal Camera Bags & Cases  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.iloc[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture build_basic_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_basic_cnn(input_shape, num_classes):\n",
    "    # Define the input layer with the specified shape.\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # First convolutional layer: 256 filters, 3x3 kernel, ReLU activation, L2 regularization.\n",
    "    x = Conv2D(256, (3, 3), activation='relu', kernel_regularizer=l2(0.001))(inputs)\n",
    "    # Apply max pooling with a 2x2 window to downsample the feature maps.\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    # Apply dropout to reduce overfitting with a rate of 20%.\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    # Second convolutional layer: 128 filters, 3x3 kernel, ReLU activation, L2 regularization.\n",
    "    x = Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "    # Apply max pooling with a 2x2 window to downsample the feature maps.\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    # Apply dropout to reduce overfitting with a rate of 20%.\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    # Third convolutional layer: 64 filters, 3x3 kernel, ReLU activation, L2 regularization.\n",
    "    x = Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "    # Apply max pooling with a 2x2 window to downsample the feature maps.\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    # Apply dropout to reduce overfitting with a rate of 20%.\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    # Fourth convolutional layer: 32 filters, 3x3 kernel, ReLU activation, L2 regularization.\n",
    "    x = Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "    # Apply max pooling with a 2x2 window to downsample the feature maps.\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    # Apply dropout to reduce overfitting with a rate of 20%.\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    # Flatten the 3D tensor output from the last convolutional layer into a 1D vector.\n",
    "    x = Flatten()(x)\n",
    "    # Fully connected (dense) layer with 128 units, ReLU activation, L2 regularization.\n",
    "    x = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "    # Apply batch normalization to stabilize and accelerate training.\n",
    "    x = BatchNormalization()(x)\n",
    "    # Apply dropout to reduce overfitting with a rate of 50%.\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    # Output layer with units equal to the number of classes and softmax activation for classification.\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Create the model using the input and output layers defined above.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize and Compile the CNN Model with Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any previous Keras session to ensure that the model is built from scratch\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Define the input shape of the images (128x128 pixels with 3 color channels) and the number of output classes\n",
    "input_shape = (128, 128, 3)\n",
    "num_classes = 13\n",
    "\n",
    "# Build a basic CNN model using the input shape and number of classes defined above\n",
    "model = build_basic_cnn(input_shape, num_classes)\n",
    "\n",
    "# Compile the model with the Adam optimizer, categorical cross-entropy loss function, and accuracy as the metric\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define a callback to stop training early if the validation loss does not improve for 10 epochs, restoring the best weights\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Define a callback to reduce the learning rate when the validation loss plateaus, with a minimum learning rate threshold\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train labels: (35018, 13)\n",
      "Shape of validation labels: (7515, 13)\n",
      "Shape of test labels: (7491, 13)\n",
      "Shape of batch images: (128, 128, 128, 3)\n",
      "Shape of batch labels: (128, 13)\n",
      "Shape of batch images: (128, 128, 128, 3)\n",
      "Shape of batch labels: (128, 13)\n"
     ]
    }
   ],
   "source": [
    "# Checking the shape of the labels\n",
    "print(\"Shape of train labels:\", train_labels.shape)\n",
    "print(\"Shape of validation labels:\", val_labels.shape)\n",
    "print(\"Shape of test labels:\", test_labels.shape)\n",
    "\n",
    "# Checking the structure of the datasets\n",
    "for images, labels in train_ds.take(1):\n",
    "    print(\"Shape of batch images:\", images.shape)\n",
    "    print(\"Shape of batch labels:\", labels.shape)\n",
    "\n",
    "for images, labels in val_ds.take(1):\n",
    "    print(\"Shape of batch images:\", images.shape)\n",
    "    print(\"Shape of batch labels:\", labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Model Level 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "     train_ds,\n",
    "     epochs=100,\n",
    "     validation_data=val_ds,\n",
    "     class_weight=class_weight_dict,\n",
    "     callbacks=[early_stopping, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(level_input, model, history):\n",
    "    # Construct filenames using the provided level input\n",
    "    model_filename = f'models/level{level_input}_model_image.keras'\n",
    "    config_filename = f'models/level{level_input}_config_images.pkl'\n",
    "    weights_filename = f'models/level{level_input}_weights_images.pkl'\n",
    "    history = f'models/level{level_input}_history_images.pkl'\n",
    "    \n",
    "    # Save the model to a file\n",
    "    model.save(model_filename)\n",
    "    \n",
    "    # Get the configuration and weights of the model\n",
    "    config = model.get_config()\n",
    "    weights = model.get_weights()\n",
    "    \n",
    "    # Save the model configuration to a file\n",
    "    with open(config_filename, \"wb\") as f:\n",
    "        pickle.dump(config, f)\n",
    "    \n",
    "    # Save the model weights to a file\n",
    "    with open(weights_filename, \"wb\") as f:\n",
    "        pickle.dump(weights, f)\n",
    "\n",
    "\n",
    "    # Guardar el historial de entrenamiento\n",
    "    with open(history, 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "    \n",
    "    print(f\"The model architecture and weights for level {level_input} have been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_input = 1  \n",
    "save_model(level_input, model , history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "test_predictions = model.predict(test_ds)\n",
    "\n",
    "# Convert predictions and labels to their original values\n",
    "test_pred_classes = np.argmax(test_predictions, axis=1)\n",
    "test_true_classes = np.argmax(test_labels, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Model Performance: F1-Score, Precision, Recall, and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "# Calculate F1-score\n",
    "f1 = f1_score(test_true_classes, test_pred_classes, average='weighted')\n",
    "precision = precision_score(test_true_classes, test_pred_classes, average='weighted')\n",
    "recall = recall_score(test_true_classes, test_pred_classes, average='weighted')\n",
    "\n",
    "# Print the metrics\n",
    "print(f'F1-score: {f1}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "\n",
    "# Display the classification report\n",
    "print(classification_report(test_true_classes, test_pred_classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Model Training: Loss and Accuracy Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the loss during training and validation\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the accuracy during training and validation\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
