{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGl_7yF5g3mD"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.9.1\n",
        "!pip install transformers==4.37.2\n",
        "#!pip install -q -U keras-tuner\n",
        "!pip3 install --upgrade mlflow"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### get text and image models"
      ],
      "metadata": {
        "id": "zp7aFY7cho6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_model_text = []\n",
        "models_runs = ['50c85a2deab242f1ad4085341ef08867', '6ee6adbd7e854df7bf6489386fe374f7', 'f97b6bc180cf44d98dd3df6c5261588d', '642a6cff6b534df1b64b2c37bda832e5', 'afa78a883cef4cb9957f85835b07698d']\n",
        "artifacts_dir = '/content/drive/MyDrive/final_project/bert/multiple_inputs/small_model_joined_data/models_compartida/artifacts/' + models_runs[LEVEL -1] + '/artifacts/'\n",
        "\n",
        "config_root = artifacts_dir + 'model_config.json'\n",
        "weights_root = artifacts_dir + 'model_weights.h5'\n",
        "\n",
        "with open(config_root, 'r') as file_json:\n",
        "  config = json.load(file_json)\n",
        "model = tf.keras.models.model_from_json(json.dumps(config))\n",
        "string_name = f'model_text_L{LEVEL}'\n",
        "\n",
        "globals()[string_name] = model\n",
        "globals()[string_name].load_weights(weights_root)\n",
        "globals()[string_name]._name = string_name\n",
        "globals()[string_name].summary()"
      ],
      "metadata": {
        "id": "G8lYJJVShomr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_model_image = []\n",
        "artifacts_dir_image = '/content/drive/MyDrive/final_project/bert/multiple_inputs/small_model_joined_data/models_compartida/models/images/resnet_0_64/'\n",
        "\n",
        "config_root = artifacts_dir_image + 'RESENET_60_model_config.json'\n",
        "weights_root_image = artifacts_dir_image + 'RESENET_60_model_weights.h5'\n",
        "\n",
        "with open('/content/drive/MyDrive/final_project/bert/multiple_inputs/small_model_joined_data/models_compartida/models/images/resnet/cnn_11_3ago_config.pkl', 'rb') as file_pkl:\n",
        "  config = pickle.load(file_pkl)\n",
        "with open('/content/drive/MyDrive/final_project/bert/multiple_inputs/small_model_joined_data/models_compartida/models/images/resnet/cnn_11_3ago_weights.pkl', 'rb') as file_pkl:\n",
        "  weights = pickle.load(file_pkl)\n",
        "model = tf.keras.Model.from_config(config)\n",
        "string_name = f'model_image_L{LEVEL}'\n",
        "globals()[string_name] = model\n",
        "globals()[string_name].set_weights(weights)\n",
        "globals()[string_name]._name = string_name\n",
        "globals()[string_name].summary()"
      ],
      "metadata": {
        "id": "3tr4U-JRhb29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## set traible = False to both models\n",
        "models_L1 = [model_text_L1, model_image_L1, ]\n",
        "for model in models_L1:\n",
        "  model.trainable = False"
      ],
      "metadata": {
        "id": "w2MtJh-Oh00i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build the model"
      ],
      "metadata": {
        "id": "wygbqTrch9cC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###\n",
        "input_text = Input((768, ), name='input_text')\n",
        "input_image = Input((224, 224, 3,), name='input_image')\n",
        "\n",
        "out_text = tf.nn.softmax(models_L1[0](input_text))\n",
        "out_image = models_L1[1](input_image)\n",
        "\n",
        "x_c = concatenate([out_text, out_image])\n",
        "out_layer = Dense(13,)(x_c)\n",
        "\n",
        "model = tf.keras.Model([input_text, input_image], out_layer)\n",
        "model.compile('adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy', F1Score(13, average='weighted')])"
      ],
      "metadata": {
        "id": "gYIRpyTNh8v4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Settiing up the experiment tracking"
      ],
      "metadata": {
        "id": "G7Y14t_-igis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setting up mlflow\n",
        "shared_folder = '/content/drive/MyDrive/final_project/bert/multiple_inputs/small_model_joined_data/models_compartida'\n",
        "store = '/my_runs.db'\n",
        "mlflow.set_tracking_uri('sqlite:///'+shared_folder + store)\n",
        "print(mlflow.get_tracking_uri())"
      ],
      "metadata": {
        "id": "lo1bfSfWicKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_experiment():\n",
        "  \"\"\"\n",
        "    This function creates the experiment in the experiment tracking database\n",
        "\n",
        "    Return:\n",
        "      LEVEL: int level of the category\n",
        "      MLFLOW_EXPERIMENT_NAME: str name of the experiment\n",
        "  \"\"\"\n",
        "  global LEVEL\n",
        "  global EXPERIMENT_NAME\n",
        "\n",
        "  EXPERIMENT_NAME = f'fusion model level {LEVEL}'\n",
        "  artifact_folder = 'artifacts'\n",
        "  artifact_location = os.path.join(shared_folder, artifact_folder)\n",
        "\n",
        "  try:\n",
        "    mlflow_experiment_id = mlflow.create_experiment(EXPERIMENT_NAME,\n",
        "                                                    artifact_location=artifact_location)\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "  finally:\n",
        "    print('set experiment')\n",
        "    mlflow.set_experiment(EXPERIMENT_NAME)\n"
      ],
      "metadata": {
        "id": "IwdBg8vgisR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting up graphs and metrics"
      ],
      "metadata": {
        "id": "DY8buawCi7BK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class F1Score(tf.keras.metrics.Metric):\n",
        "  \"\"\"\n",
        "    This function is a customized matric to evaluate the F1 score in the training\n",
        "  \"\"\"\n",
        "  def __init__(self, num_classes, average='macro', name='f1_score', **kwargs):\n",
        "    super(F1Score, self).__init__(name=name, **kwargs)\n",
        "    self.num_classes = num_classes\n",
        "    self.average = average\n",
        "    self.true_positives = self.add_weight(name='tp', shape=(num_classes,), initializer='zeros', dtype=tf.float32)\n",
        "    self.false_positives = self.add_weight(name='fp', shape=(num_classes,), initializer='zeros', dtype=tf.float32)\n",
        "    self.false_negatives = self.add_weight(name='fn', shape=(num_classes,), initializer='zeros', dtype=tf.float32)\n",
        "\n",
        "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "    y_pred = tf.argmax(y_pred, axis=-1)\n",
        "    y_true = tf.argmax(y_true, axis=-1)\n",
        "\n",
        "    for i in range(self.num_classes):\n",
        "      y_pred_i = tf.cast(y_pred == i, tf.float32)\n",
        "      y_true_i = tf.cast(y_true == i, tf.float32)\n",
        "\n",
        "      tp = tf.reduce_sum(y_true_i * y_pred_i)\n",
        "      fp = tf.reduce_sum(y_pred_i) - tp\n",
        "      fn = tf.reduce_sum(y_true_i) - tp\n",
        "\n",
        "      self.true_positives[i].assign(self.true_positives[i] + tp)\n",
        "      self.false_positives[i].assign(self.false_positives[i] + fp)\n",
        "      self.false_negatives[i].assign(self.false_negatives[i] + fn)\n",
        "\n",
        "  def result(self):\n",
        "    precision = self.true_positives / (self.true_positives + self.false_positives + K.epsilon())\n",
        "    recall = self.true_positives / (self.true_positives + self.false_negatives + K.epsilon())\n",
        "    f1 = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
        "\n",
        "    if self.average == 'macro':\n",
        "      return tf.reduce_mean(f1)\n",
        "    elif self.average == 'weighted':\n",
        "      weights = self.true_positives + self.false_negatives\n",
        "      return tf.reduce_sum(f1 * weights) / tf.reduce_sum(weights)\n",
        "    else:\n",
        "      raise ValueError(f'Unknown average type: {self.average}')\n",
        "\n",
        "  def reset_state(self):\n",
        "    for i in range(self.num_classes):\n",
        "      self.true_positives[i].assign(0)\n",
        "      self.false_positives[i].assign(0)\n",
        "      self.false_negatives[i].assign(0)\n"
      ],
      "metadata": {
        "id": "dgPMXIUziwIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_plot(model):\n",
        "  \"\"\"\n",
        "    This function creates the model architecture graph.\n",
        "  \"\"\"\n",
        "  tf.keras.utils.plot_model(model, '/content/plot_model.png',\n",
        "                                        show_shapes=True,\n",
        "                                        show_dtype=True,\n",
        "                                        show_layer_names=True,\n",
        "                                        show_layer_activations=True,\n",
        "                                        rankdir='PR'\n",
        "                                        )\n",
        "def plots_gra(history, save=None):\n",
        "  \"\"\"\n",
        "    This function creates the losses and accuracy plots\n",
        "  \"\"\"\n",
        "  metrics = ['loss', 'accuracy']\n",
        "\n",
        "  fig, axis = plt.subplots(2,2, figsize=(10, 8))\n",
        "\n",
        "  axis[0, 0].plot(history.history['loss'])\n",
        "  axis[0, 0].set_xlabel('epochs')\n",
        "  axis[0, 0].set_ylabel('loss')\n",
        "\n",
        "  axis[0, 1].plot(history.history[f'val_loss'])\n",
        "  axis[0, 1].set_xlabel('epochs')\n",
        "  axis[0, 1].set_ylabel(f'val_loss')\n",
        "\n",
        "  axis[1, 0].plot(history.history['accuracy'])\n",
        "  axis[1, 0].set_xlabel('epochs')\n",
        "  axis[1, 0].set_ylabel('accuracy')\n",
        "\n",
        "  axis[1, 1].plot(history.history[f'val_accuracy'])\n",
        "  axis[1, 1].set_xlabel('epochs')\n",
        "  axis[1, 1].set_ylabel(f'val_accuracy')\n",
        "\n",
        "  fig.tight_layout()\n",
        "\n",
        "  if save:\n",
        "    plt.savefig('/content/metrics.png')\n",
        "    #fig.savefig(save_root + '/metrics.png')\n",
        "    #plt.close()\n",
        "  plt.show()\n",
        "\n",
        "def get_consufion_matrix(set_to_evaluate, true_labels, name):\n",
        "\n",
        "  \"\"\"\n",
        "      this function is to create the confusion matrix with my results\n",
        "      inputs:\n",
        "        set_to_evaluate = set of embeddings to evaluate\n",
        "        true_labels = the labels of set_to_evaluate\n",
        "        root = Path in where it confussion matrix will be save\n",
        "  \"\"\"\n",
        "\n",
        "  global class_names\n",
        "\n",
        "  predict = model.predict(set_to_evaluate)\n",
        "  predict = np.argmax(predict, axis=1)\n",
        "\n",
        "  cm = confusion_matrix(true_labels, predict)\n",
        "\n",
        "  # Crear una figura y un eje\n",
        "  fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "  # Crear el mapa de calor de la matriz de confusión\n",
        "  sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names, ax=ax)\n",
        "\n",
        "  # Añadir etiquetas y título\n",
        "  ax.set_xlabel('Predicted labels')\n",
        "  ax.set_ylabel('True labels')\n",
        "  ax.set_title('Confusion Matrix')\n",
        "\n",
        "  fig.tight_layout()\n",
        "  if name:\n",
        "    #fig.savefig('/content/drive/MyDrive/final_project/bert/multiple_inputs/models/0.9330/con_matrix.png')\n",
        "    #print('guardo')\n",
        "    fig.savefig(f'/content/con_matrix_{name}.png')"
      ],
      "metadata": {
        "id": "gMCfdKNijB1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### setting callbacks and clear enviroment functions\n",
        "# Funtion to clear my dir\n",
        "def clear_enviroment():\n",
        "  tf.keras.backend.clear_session()\n",
        "  if 'model' in dir() :\n",
        "    print(\"i am cutting\")\n",
        "    del(model)\n",
        "\n",
        "# Callbacks\n",
        "call_early = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=9, restore_best_weights=True)\n",
        "class CustomCallback(tf.keras.callbacks.Callback):\n",
        "  \"\"\"\n",
        "    Customizer class to log the metrics model in mlflow\n",
        "  \"\"\"\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    \"\"\"\n",
        "      This function log the metrics on epoch end\n",
        "    \"\"\"\n",
        "    mlflow.log_metric('loss', logs.get('loss'), step=epoch)\n",
        "    mlflow.log_metric('accuracy', logs.get('accuracy'), step=epoch)\n",
        "    mlflow.log_metric('val_loss', logs.get('loss'), step=epoch)\n",
        "    mlflow.log_metric('val_accuracy', logs.get('val_accuracy'), step=epoch)\n",
        "\n",
        "    ## f1_score\n",
        "    mlflow.log_metric('f1_score', logs.get('f1_score'), step=epoch)\n",
        "    mlflow.log_metric('val_f1_score', logs.get('val_f1_score'), step=epoch)\n",
        "    \"\"\"\n",
        "    mlflow.log_metric(\"accuracy\", logs[\"accuracy\"])\n",
        "    mlflow.log_metric(\"loss\", logs[\"loss\"])"
      ],
      "metadata": {
        "id": "0cTdIWT2jES9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obtain the dato for level"
      ],
      "metadata": {
        "id": "fhqi1bLukQ8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.RandomFlip(\"horizontal\"),\n",
        "  layers.RandomRotation(0.03),\n",
        "])\n",
        "\n",
        "def load_image(file_name):\n",
        "  raw = tf.io.read_file(file_name)\n",
        "  tensor = tf.image.decode_jpeg(raw, channels=3)\n",
        "  tensor2 = tf.image.resize(tensor, [224, 224], preserve_aspect_ratio=True)\n",
        "  shape = tf.shape(tensor2)\n",
        "  h = (224 - shape[0]) //2\n",
        "  w = (224 - shape[1]) //2\n",
        "  h = tf.maximum(h, 0)\n",
        "  w = tf.maximum(w, 0)\n",
        "  tensor = tf.image.pad_to_bounding_box(tensor2, int(h.numpy()), int(w.numpy()), 224, 224)\n",
        "  mask = tf.image.pad_to_bounding_box(tf.ones_like(tensor2), h, w, 224, 224)\n",
        "  tensor = tf.cast(tensor, tf.float32) / 255.0\n",
        "  tensor = tensor * mask + (1 - mask) * 0.5\n",
        "  tensor = data_augmentation(tensor)\n",
        "  return tensor\n",
        "\n",
        "\n",
        "def get_mask_of_filtered(set_no, set_fil):\n",
        "  list_index = []\n",
        "  m = 0\n",
        "  for n in range(set_no.shape[0]):\n",
        "    if set_no.iloc[n,0] == set_fil.iloc[m,0]:\n",
        "      list_index.append(n)\n",
        "      m += 1\n",
        "\n",
        "  list_fil = [False]*set_no.shape[0]\n",
        "  ran_list_fil = range(set_no.shape[0])\n",
        "\n",
        "  for ran in ran_list_fil:\n",
        "    if ran in list_index:\n",
        "      list_fil[ran] = True\n",
        "\n",
        "  return list_fil\n",
        "\n",
        "\n",
        "def load_data():\n",
        "  \"\"\"\n",
        "    This function obtains the data, like data.csv and embeddings from bert.\n",
        "\n",
        "    Return:\n",
        "      train: Dataframe.\n",
        "      test: Daraframe.\n",
        "      val: Dataframe.\n",
        "      train_data_join: np.array.\n",
        "      test_data_join: np.array.\n",
        "      val_data_join: np.array.\n",
        "  \"\"\"\n",
        "\n",
        "  global train\n",
        "  global test\n",
        "  global val\n",
        "  global train_data_join\n",
        "  global test_data_join\n",
        "  global val_data_join\n",
        "\n",
        "  print('loaded data')\n",
        "\n",
        "  train = pd.read_csv('/content/drive/MyDrive/final_project/bert/dataset/train.csv')\n",
        "  test = pd.read_csv('/content/drive/MyDrive/final_project/bert/dataset/test.csv')\n",
        "  val = pd.read_csv('/content/drive/MyDrive/final_project/bert/dataset/val.csv')\n",
        "\n",
        "  train_filtered = pd.read_csv('/content/drive/MyDrive/final_project/bert/multiple_inputs/small_model_joined_data/models_compartida/Final/imagenes/train_filtered.csv')\n",
        "  test_filtered = pd.read_csv('/content/drive/MyDrive/final_project/bert/multiple_inputs/small_model_joined_data/models_compartida/Final/imagenes/test_filtered.csv')\n",
        "  val_filtered = pd.read_csv('/content/drive/MyDrive/final_project/bert/multiple_inputs/small_model_joined_data/models_compartida/Final/imagenes/val_filtered.csv')\n",
        "\n",
        "  mask = get_mask_of_filtered(train, train_filtered)\n",
        "  train = train[mask]\n",
        "  with open(\"/content/drive/MyDrive/final_project/bert/dataset/embeddings_joined/train_embeddings.pkl\", \"rb\") as f:\n",
        "    train_data_join = pickle.load(f)\n",
        "    train_data_join = np.array(train_data_join)[mask]\n",
        "\n",
        "  mask = get_mask_of_filtered(test, test_filtered)\n",
        "  test = test[mask]\n",
        "  with open(\"/content/drive/MyDrive/final_project/bert/dataset/embeddings_joined/test_embeddings.pkl\", \"rb\") as f:\n",
        "    test_data_join = pickle.load(f)\n",
        "    test_data_join = np.array(test_data_join)[mask]\n",
        "\n",
        "  mask = get_mask_of_filtered(val, val_filtered)\n",
        "  val = val[mask]\n",
        "  with open(\"/content/drive/MyDrive/final_project/bert/dataset/embeddings_joined/val_embeddings.pkl\", \"rb\") as f:\n",
        "    val_data_join = pickle.load(f)\n",
        "    val_data_join = np.array(val_data_join)[mask]\n",
        "\n",
        "  del(train_filtered)\n",
        "  del(test_filtered)\n",
        "  del(val_filtered)\n",
        "\n",
        "def get_data():\n",
        "   \"\"\"\n",
        "    This function creates the Datasets to train and validate the model.\n",
        "\n",
        "    Return:\n",
        "      dataset_train: tf.data.Dataset.\n",
        "      dataset_test: tf.data.Dataset.\n",
        "  \"\"\"\n",
        "  global LEVEL\n",
        "  global NUMBER_OUT\n",
        "  global COMPUTE_CLASS\n",
        "  global train_label_le\n",
        "  global train_label_cate\n",
        "  global test_label_le\n",
        "  global test_label_cate\n",
        "  global val_label_le\n",
        "  global val_label_cate\n",
        "  global dataset_train\n",
        "  global dataset_test\n",
        "  global train\n",
        "  global test\n",
        "  global val\n",
        "  global train_data_join\n",
        "  global test_data_join\n",
        "  global val_data_join\n",
        "  global class_names\n",
        "\n",
        "  load_data()\n",
        "\n",
        "  artifacts = '/content/drive/MyDrive/final_project/bert/multiple_inputs/small_model_joined_data/models_compartida/artifacts/Label_encoders'\n",
        "  ima_folder = '/content/drive/MyDrive/final_project/bert/multiple_inputs/small_model_joined_data/models_compartida/Final/imagenes/img/product_images/'\n",
        "\n",
        "  train_labels = train[f'subcat{LEVEL}_name']\n",
        "  test_labels = test[f'subcat{LEVEL}_name']\n",
        "  val_labels = val[f'subcat{LEVEL}_name']\n",
        "\n",
        "  train_images_names = np.array(train['image'])\n",
        "  test_images_names = np.array(test['image'])\n",
        "  val_images_names = np.array(val['image'])\n",
        "\n",
        "  if 1 == LEVEL:\n",
        "    train_labels[pd.isna(train_labels)] = 'Other'\n",
        "    test_labels[pd.isna(test_labels)] = 'Other'\n",
        "    val_labels[pd.isna(val_labels)] = 'Other'\n",
        "  else:\n",
        "    mask_null_train = ~pd.isna(train_labels)\n",
        "    mask_null_test = ~pd.isna(test_labels)\n",
        "    mask_null_val = ~pd.isna(val_labels)\n",
        "\n",
        "    train_labels = train_labels[mask_null_train]\n",
        "    test_labels = test_labels[mask_null_test]\n",
        "    val_labels = val_labels[mask_null_val]\n",
        "\n",
        "    train_data_join = train_data_join[mask_null_train]\n",
        "    test_data_join = test_data_join[mask_null_test]\n",
        "    val_data_join = val_data_join[mask_null_val]\n",
        "\n",
        "    train_images_names = ima_folder + train_images_names[mask_null_train]\n",
        "    test_images_names = ima_folder + test_images_names[mask_null_test]\n",
        "    val_images_names = ima_folder + val_images_names[mask_null_val]\n",
        "\n",
        "\n",
        "  listdis = os.listdir(artifacts)\n",
        "\n",
        "  if f'label_encoder_level{LEVEL}.pkl' in listdis:\n",
        "    with open(f'{artifacts}/label_encoder_level{LEVEL}.pkl', 'rb') as f:\n",
        "      le = pickle.load(f)\n",
        "      train_label_le = le.transform(train_labels)\n",
        "    print('loaded')\n",
        "  else:\n",
        "    le = LabelEncoder()\n",
        "    train_label_le = le.fit_transform(train_labels)\n",
        "    with open(f'{artifacts}/label_encoder_level{LEVEL}.pkl', 'wb') as f:\n",
        "      pickle.dump(le, f)\n",
        "    print('created and saved')\n",
        "\n",
        "  class_names = le.classes_\n",
        "  train_label_cate = to_categorical(train_label_le)\n",
        "  test_label_le = le.transform(test_labels)\n",
        "  test_label_cate = to_categorical(test_label_le)\n",
        "  val_label_le = le.transform(val_labels)\n",
        "  val_label_cate = to_categorical(val_label_le)\n",
        "  NUMBER_OUT = len(train_labels.unique())\n",
        "  print(len(train_label_cate))\n",
        "  print(len(test_label_cate))\n",
        "  print(NUMBER_OUT)\n",
        "\n",
        "  COMPUTE_CLASS = compute_class_weight(class_weight=\"balanced\", classes=np.unique(train_label_le), y=train_label_le)\n",
        "  COMPUTE_CLASS = {i:value for i, value in enumerate(COMPUTE_CLASS) }\n",
        "  print(COMPUTE_CLASS)\n",
        "\n",
        "  print(train_images_names.shape, train_data_join.shape)\n",
        "\n",
        "  dataset_train = tf.data.Dataset.from_tensor_slices(((train_data_join, train_images_names), train_label_cate))\n",
        "  dataset_train = dataset_train.map(lambda x, y: ((x[0], (load_image(ima_folder + x[1]))), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "  dataset_train = dataset_train.batch(32).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "  dataset_test = tf.data.Dataset.from_tensor_slices(((val_data_join, val_images_names), val_label_cate))\n",
        "  dataset_test = dataset_test.map(lambda x, y: ((x[0], (load_image(ima_folder + x[1]))), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "  dataset_test = dataset_test.batch(32).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
      ],
      "metadata": {
        "id": "i8Tr4LhxkULx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiment tracking"
      ],
      "metadata": {
        "id": "osEmNUT_jXiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EXPERIMENT_NUMBER = 1\n",
        "EXPERIMENT_NAME = 'Fusion Models'"
      ],
      "metadata": {
        "id": "fU-roaSfjaOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LEVEL = 1\n",
        "create_experiment()\n",
        "get_data()"
      ],
      "metadata": {
        "id": "YUh61GQLjelY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "THRESHOLD = 0.70 ### threshold to exceed to save the model\n",
        "EPOCHS = 1000\n",
        "with open('/content/drive/MyDrive/final_project/bert/multiple_inputs/small_model_joined_data/models_compartida/my_runs.db'):\n",
        "\n",
        "  mlflow.start_run(run_name=f'{EXPERIMENT_NAME}_N_{EXPERIMENT_NUMBER}')\n",
        "  clear_enviroment()\n",
        "\n",
        "  histoty = model.fit(dataset_train, epochs=EPOCHS, validation_data=dataset_test,  class_weight=COMPUTE_CLASS, callbacks=[call_early, CustomCallback()])\n",
        "\n",
        "  ### Obtain the graphs and metrics\n",
        "  get_model_plot(model, )\n",
        "  plots_gra(history, True)\n",
        "  #test\n",
        "  get_consufion_matrix(test_data_join, test_label_le, 'test')\n",
        "  #val\n",
        "  get_consufion_matrix(val_data_join, val_label_le, 'val')\n",
        "\n",
        "  if 'metrics.png' in os.listdir('/content'):\n",
        "    os.rename('/content/metrics.png', '/content/old_metrics.png')\n",
        "    print('this is the old metric')\n",
        "    fig = plt.figure(figsize=(10, 10))\n",
        "    old_img = tf.keras.preprocessing.image.load_img('/content/old_metrics.png')\n",
        "    plt.imshow(old_img)\n",
        "\n",
        "  ### Obtain the predictions for validation and test sets\n",
        "  predict_test = model.predict(test_data_join)\n",
        "  predict_test = np.argmax(predict_test, axis=1)\n",
        "  f1_test = f1_score(test_label_le, predict_test, average='weighted')\n",
        "  print(f'{f1_test=}')\n",
        "\n",
        "  predict_val = model.predict(val_data_join)\n",
        "  predict_val = np.argmax(predict_val, axis=1)\n",
        "  f1_val = f1_score(val_label_le, predict_val, average='weighted')\n",
        "  print(f'val = {f1_val=}')\n",
        "\n",
        "  if f1_val >= THRESHOLD and f1_test >= THRESHOLD :\n",
        "    print('the threshold has been overcome')\n",
        "    config = model.get_config()\n",
        "    weights = model.get_weights()\n",
        "    model.save('/content/model.keras')\n",
        "    model.save_weights('model_weights.h5')\n",
        "    model_config = model.to_json()\n",
        "\n",
        "    with open('model_config.json', 'w') as json_file:\n",
        "      json_file.write(model_config)\n",
        "\n",
        "    mlflow.log_artifact('model_weights.h5',)\n",
        "    mlflow.log_artifact('model_config.json',)\n",
        "    mlflow.log_artifact('model.keras')\n",
        "\n",
        "EXPERIMENT_NUMBER += 1\n"
      ],
      "metadata": {
        "id": "k5oUV5vSkwnW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}